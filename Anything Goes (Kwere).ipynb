{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kwere Character-Level Language Model Using PyTorch LSTMs\n",
    "\n",
    "This notebook is nearly identical to \"Anything Goes (Swahili)\". The pretrain-train relationship is just inverted: pre-train on Swahili, fine-tune on Kwere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "\n",
    "I reached a cross entropy of approximately 1.4 for validation and 1.47 for test. This accuracy was about 67% for the test set.\n",
    "\n",
    "A lot of variable decisions were surprising, for example: `carry_hidden_state` reduced performance and any more than a very small subset of the Swahili dataset would reduce performance (possibly because it would overwhelm the small amount of Kwere data).\n",
    "\n",
    "[Click here for a full list of trials run](https://ui.neptune.ai/gregrolwes/Bantu-Language-Modeling/experiments?viewId=standard-view&sortBy=%5B%22timeOfCreation%22%5D&sortDirection=%5B%22descending%22%5D&sortFieldType=%5B%22native%22%5D&sortFieldAggregationMode=%5B%22auto%22%5D&trashed=false&suggestionsEnabled=true&tags=%5B%22kwere%22%2C%22anything%20goes%22%5D&lbViewUnpacked=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Dictionary containing all parameters for ease of tuning. These will be logged to the neptune logger below.\n",
    "\n",
    "**To add test data, enter the test file name in the `test_data` parameter.**\n",
    "\n",
    "Select Parameter Descriptions:\n",
    " - `experiment_name`: identifier to be used in logging\n",
    " - `tags`: also for logging and filtering trials\n",
    " - `seq_len`: length of character lists fed to the model\n",
    " - `num_layers`: LSTM layers\n",
    " - `carry_hidden_state`: whether or not to perpetuate the hidden state between sequences\n",
    " - `pretrain_lr`: the learning rate to use while pretraining\n",
    " - `swahili_percentage`: the percentage of the Swahili data to pretrain with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'experiment_name': \"Kwere\",\n",
    "    'tags': [\"kwere\", \"swahili-pretrained\", \"anything goes\"],\n",
    "    'epochs': 10,\n",
    "    'hidden_size': 512,\n",
    "    'seq_len': 500,\n",
    "    'num_layers': 4,\n",
    "    'dropout': 0.3,\n",
    "    'lr': 0.001,\n",
    "    'carry_hidden_state': False,\n",
    "    'val_split': 0.3,\n",
    "    'kwere_train': \"./cwe-train.txt\",\n",
    "    'pretrain_epochs': 5,\n",
    "    'pretrain_lr': 0.0001,\n",
    "    'swahili_percentage': 0.01, \n",
    "    'swahili': \"./sw-train.txt\",\n",
    "    'test_data': \"./cwe-test.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging\n",
    "For this project I used a logging library / UI called [Neptune.ai](https://neptune.ai/) to track all runs and their respective hyperparameters. Since the API key for this is only in my local `bash_profile`, **this cell will throw an error**, but I'll conditionalize all the logging in the notebook so errors won't be thrown beyond this cell.\n",
    "\n",
    "To view the logs from my runs, visit the project url [here](https://ui.neptune.ai/gregrolwes/Bantu-Language-Modeling/experiments?viewId=standard-view&sortBy=%5B%22timeOfCreation%22%5D&sortDirection=%5B%22descending%22%5D&sortFieldType=%5B%22native%22%5D&sortFieldAggregationMode=%5B%22auto%22%5D&trashed=false&suggestionsEnabled=true&tags=%5B%22kwere%22%2C%22anything%20goes%22%5D&lbViewUnpacked=true). Note projects are tagged with which language they're targeting, and whether or not they using the \"Anything Goes\" or \"From Scratch\" implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/gregrolwes/Bantu-Language-Modeling/e/BAN-33\n"
     ]
    }
   ],
   "source": [
    "is_logging = False\n",
    "\n",
    "import neptune\n",
    "\n",
    "neptune.init('gregrolwes/Bantu-Language-Modeling')\n",
    "\n",
    "neptune.create_experiment(\n",
    "            name=PARAMS['experiment_name'],\n",
    "            tags=PARAMS['tags'],\n",
    "            params=PARAMS\n",
    "        )\n",
    "\n",
    "# reach this if the above logger initialization passes\n",
    "is_logging = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Seed\n",
    "Make the experiment reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class\n",
    "The `Dataset` class generates a list of all unique characters found in the supplied data, number of total characters, number of unique characters, mappings from characters to their respective ID, mappings from chracter IDs to characters for making outputs readable, and a data tensor of every character converted to its ID.\n",
    "\n",
    "The `Dataset` will also generate a `~` character to be used in place of any characters unknown to the model (i.e. anything not in the training set). See the `clean_data` function below.\n",
    "\n",
    "Inputs:\n",
    " - `raw_data`: `string` of all characters from the provided data in order\n",
    " - `device`: `torch.device` of either `cuda` or `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, raw_data: str, device: torch.device):\n",
    "        self.chars = set(list(set(raw_data)))\n",
    "        self.chars.add('~')\n",
    "        self.data_size, self.vocab_size = len(raw_data), len(self.chars)\n",
    "        print(\"{} characters, {} unique\".format(self.data_size, self.vocab_size))\n",
    "        \n",
    "        self.char_to_idx = { char: idx for idx, char in enumerate(self.chars) }\n",
    "        self.idx_to_char = { idx: char for idx, char in enumerate(self.chars) }\n",
    "        \n",
    "        self.data = torch.tensor([self.char_to_idx[char] for char in list(raw_data)]).unsqueeze(1).to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "The `clean_data` function removes any unknown chracters in the provided data and replaces them with the deisgnated unknown chracter of `~`. I'm essentially forfeiting these characters if they ever appear in the testing data, since I likely couldn't get them correct anyway considering the model did not see them during training (unless they appear in the Swahili data, but see my explanation below for that decision).\n",
    "\n",
    "Inputs:\n",
    " - `raw_data`: `string` of raw data read directly from file\n",
    " - `known_chars`: `list` of `string` to be included in the data. Everything not in this list will be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(raw_data: str, known_chars: str) -> str:\n",
    "    cleaned = \"\"\n",
    "    for char in raw_data:\n",
    "        if char not in known_chars:\n",
    "            cleaned += \"~\"\n",
    "        else:\n",
    "            cleaned += char\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "Load the Kwere training data and split based on the provided ratio. Then load the percentage of the Swahili data requested (see `PARAMS`). Finally, if a test file is provided in `PARAMS`, load the test data.\n",
    "\n",
    "The validation, Swahili, and test data are all cleaned of unknown chracters. I chose to exclude any chracters found in the Swahili data but not found in the Kwere training data for the sake of staying as true to the Kwere language as possible (in the event Swahili uses a character that Kwere does not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Kwere training data:\n",
      "\t422402 characters, 32 unique\n",
      "Loading Kwere validation data:\n",
      "\t181030 characters, 32 unique\n",
      "Loading Swahili data:\n",
      "\t392610 characters, 32 unique\n",
      "Loading testing data:\n",
      "\t61717 characters, 32 unique\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Kwere training data:\", end=\"\\n\\t\")\n",
    "raw_kwere = open(PARAMS['kwere_train'], 'r').read()\n",
    "kwere_train_size, kwere_val_size = int(len(raw_kwere)*(1-PARAMS['val_split'])), int(len(raw_kwere)*PARAMS['val_split'])\n",
    "\n",
    "kwere_train = Dataset(raw_kwere[:kwere_train_size], device)\n",
    "\n",
    "print(\"Loading Kwere validation data:\", end=\"\\n\\t\")\n",
    "cleaned_kwere_val_data = clean_data(raw_kwere[kwere_train_size:], kwere_train.chars)\n",
    "kwere_val = Dataset(cleaned_kwere_val_data, device)\n",
    "\n",
    "\n",
    "if PARAMS['swahili_percentage'] > 0:\n",
    "    print(\"Loading Swahili data:\", end=\"\\n\\t\")\n",
    "    raw_swahili = open(PARAMS['swahili'], 'r').read()\n",
    "    swahili_size = int(len(raw_swahili) * PARAMS['swahili_percentage'])\n",
    "\n",
    "    cleaned_swahili_data = clean_data(raw_swahili[:swahili_size], kwere_train.chars)\n",
    "    swahili = Dataset(cleaned_swahili_data, device)\n",
    "\n",
    "\n",
    "if len(PARAMS['test_data']) > 0:\n",
    "    print(\"Loading testing data:\", end=\"\\n\\t\")\n",
    "    raw_test = open(PARAMS['test_data'], 'r').read()\n",
    "\n",
    "    cleaned_test_data = clean_data(raw_test, kwere_train.chars)\n",
    "    test_data = Dataset(cleaned_test_data, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Declaration\n",
    "The model is very similar to those I've used in past challenges: a multilayer LSTM with dropout. I've also added the ability to input a hidden state so the state can be carried between sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers, dropout):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, input_size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            dropout = dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        embedding = self.embedding(input_seq)\n",
    "        output, hidden_state = self.lstm(embedding, hidden_state)\n",
    "        output = self.fc(self.dropout(output))\n",
    "        return output, (hidden_state[0].detach(), hidden_state[1].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "As defined in the challenge requirements, I'm using a cross entropy loss customized to use log base 2 rather than the typical natural log used in PyTorch.\n",
    "\n",
    "I've also added an assertion making sure no probability distribution sums to more than 1/10,000 plus or minus 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(outputs, targets):\n",
    "    batch_size = outputs.shape[0]\n",
    "    outputs = nn.functional.softmax(outputs, dim=-1)\n",
    "    \n",
    "    for prob_dist_sum in torch.sum(outputs, dim=1):\n",
    "        assert(abs(prob_dist_sum - 1) < 0.0001), \"The sum of all probabilities for a character should be 1.0, but got {}\".format(prob_dist_sum)\n",
    "    \n",
    "    outputs = torch.log2(outputs)\n",
    "    outputs = outputs[range(batch_size), targets]\n",
    "\n",
    "    return -torch.mean(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_acc(outputs, targets):\n",
    "    corrects = 0\n",
    "    outputs = nn.functional.softmax(outputs, dim=-1)\n",
    "    \n",
    "    for idx, output in enumerate(outputs):\n",
    "        corrects += 1 if torch.argmax(output) == targets[idx] else 0\n",
    "\n",
    "    return corrects / len(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(torch.Tensor([1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Declaration\n",
    "Based on `PARAMS` and the determined `vocab_size` of the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(\n",
    "    kwere_train.vocab_size, \n",
    "    kwere_train.vocab_size, \n",
    "    PARAMS['hidden_size'], \n",
    "    PARAMS['num_layers'],\n",
    "    PARAMS['dropout'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "Using an Adam optimizer, learning rate set in `PARAMS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = cross_entropy_loss\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=PARAMS['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Modifier\n",
    "The `set_lr` function is meant to modify the learning rate between pretraining and fine-tuning to avoid overfitting on the Swahili data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lr(optimizer: torch.optim.Optimizer, lr: int):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(32, 32)\n",
       "  (lstm): LSTM(32, 512, num_layers=4, dropout=0.3)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=32, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check for NaNs, used in debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_nan(t: torch.Tensor) -> bool:\n",
    "    if torch.sum(torch.isnan(t)) > 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function\n",
    "Standard train function taking `seq_len` characters at a time. For each character in the series, the LSTM will predict the next character based on the previous character and the character history (represented by the hidden state). \n",
    "\n",
    "The hidden state is optionally carried between sequences, so events like a sequence ending mid-word should have no negative effect. I've made this optional because while it could help with cutoff words, I think restarting the hidden state every sequence could also be beneficial as a sort of dropout, in the event a particularly difficult sequence causes the hidden state to be thrown off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, data, seq_len):\n",
    "    ptr = 0\n",
    "    n = 0\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    hidden_state = None\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    while ptr + seq_len + 1 < len(data):\n",
    "        input_seq = data[ptr:ptr+seq_len].to(device)\n",
    "        target_seq = data[ptr+1:ptr+seq_len+1].to(device)\n",
    "\n",
    "        if hidden_state is not None:\n",
    "            if has_nan(hidden_state[0]) or has_nan(hidden_state[1]):\n",
    "                hidden_state = None\n",
    "        output, hidden_state = model(input_seq, hidden_state if PARAMS['carry_hidden_state'] else None)\n",
    "\n",
    "        try:\n",
    "            loss = criterion(torch.squeeze(output), torch.squeeze(target_seq))\n",
    "            assert(not torch.isnan(loss)), \"The loss shouldn't be nan\"\n",
    "            running_loss += loss.item()\n",
    "            running_acc += get_acc(torch.squeeze(output), torch.squeeze(target_seq))\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            n += 1\n",
    "        except AssertionError as err:\n",
    "            print(\"An assertion failed, skipping for now but this shouldn't happen often:\\n\\t{}\".format(err))\n",
    "\n",
    "        ptr += seq_len\n",
    "\n",
    "    return running_loss/n, running_acc/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Function\n",
    "Standard test function with optional carried hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, data, seq_len):\n",
    "    ptr = 0\n",
    "    n = 0\n",
    "    running_loss = 0\n",
    "    running_acc = 0\n",
    "    hidden_state = None\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    while ptr + seq_len + 1 < len(data):\n",
    "        input_seq = data[ptr:ptr+seq_len]\n",
    "        target_seq = data[ptr+1:ptr+seq_len+1]\n",
    "\n",
    "        if hidden_state is not None:\n",
    "            if has_nan(hidden_state[0]) or has_nan(hidden_state[1]):\n",
    "                hidden_state = None\n",
    "        output, hidden_state = model(input_seq, hidden_state if PARAMS['carry_hidden_state'] else None)\n",
    "\n",
    "        try:\n",
    "            loss = criterion(torch.squeeze(output), torch.squeeze(target_seq))\n",
    "            assert(not torch.isnan(loss)), \"The loss shouldn't be nan\"\n",
    "            running_loss += loss.item()\n",
    "            running_acc += get_acc(torch.squeeze(output), torch.squeeze(target_seq))\n",
    "            \n",
    "            n += 1\n",
    "        except AssertionError as err:\n",
    "            print(\"An assertion failed, skipping for now but this shouldn't happen often:\\n\\t{}\".format(err))\n",
    "\n",
    "        ptr += seq_len\n",
    "        \n",
    "    return running_loss/n, running_acc/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function Verification\n",
    "Based on the equation for cross entropy, a randomized model's loss should on average be $log_2(vocab\\_size)$.\n",
    "\n",
    "This number should also be the target to verify that the model is learning. Any loss lower than this value has learned a non-zero amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is 32, so cross entropy with no training should be approximately 5.0\n",
      "Untrained loss: 5.015613420233542\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab size is {}, so cross entropy with no training should be approximately {}\".format(kwere_train.vocab_size, math.log(kwere_train.vocab_size, 2)))\n",
    "print(\"Untrained loss:\", end=\" \")\n",
    "print(test(rnn, loss_fn, kwere_val, PARAMS['seq_len']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Pretrain Epoch 1 -----------------\n",
      "\tPretrain Loss: 3.93833114599726\n",
      "--- Pretrain Epoch 2 -----------------\n",
      "\tPretrain Loss: 3.266909222086524\n",
      "--- Pretrain Epoch 3 -----------------\n",
      "\tPretrain Loss: 3.0710979352331464\n",
      "--- Pretrain Epoch 4 -----------------\n",
      "\tPretrain Loss: 2.9373063609858225\n",
      "--- Pretrain Epoch 5 -----------------\n",
      "\tPretrain Loss: 2.8453641997780768\n"
     ]
    }
   ],
   "source": [
    "if PARAMS['swahili_percentage'] > 0:\n",
    "    set_lr(optimizer, PARAMS['pretrain_lr'])\n",
    "    \n",
    "    for epoch in range(0, PARAMS['pretrain_epochs']):\n",
    "        print(\"-\"*3 + \" Pretrain Epoch {} \".format(epoch+1) + \"-\"*17)\n",
    "\n",
    "        print(\"\\tPretrain Loss:\", end=\" \")\n",
    "        pretrain_loss = train(rnn, loss_fn, optimizer, swahili, PARAMS['seq_len'])\n",
    "        print(pretrain_loss)\n",
    "        \n",
    "        if is_logging:\n",
    "            neptune.log_metric(\"Pretrain Loss\", pretrain_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 14 -------------------------\n",
      "\tTrain Loss: 1.233\t\t|\tTrain Accuracy: 71.93%\n",
      "\tValidation Loss: 1.401\t\t|\tValidation Accuracy: 69.65%\n",
      "--- Epoch 15 -------------------------\n",
      "\tTrain Loss: 1.222\t\t|\tTrain Accuracy: 72.14%\n",
      "\tValidation Loss: 1.404\t\t|\tValidation Accuracy: 69.69%\n",
      "--- Epoch 16 -------------------------\n",
      "\tTrain Loss: "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-110-a440295b92b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\tTrain Loss:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwere_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPARAMS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'seq_len'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{:.3f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t|\\tTrain Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\" \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-106-c9e5cf417d1f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, criterion, optimizer, data, seq_len)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \"\"\"\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    125\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    126\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "set_lr(optimizer, PARAMS['lr'])\n",
    "\n",
    "for epoch in range(0, PARAMS['epochs']):\n",
    "    print(\"-\"*3 + \" Epoch {} \".format(epoch+1) + \"-\"*25)\n",
    "    \n",
    "    print(\"\\tTrain Loss:\", end=\" \")\n",
    "    train_loss, train_acc = train(rnn, loss_fn, optimizer, kwere_train, PARAMS['seq_len'])\n",
    "    print(\"{:.3f}\".format(train_loss), end=\"\\t\")\n",
    "    print(\"\\t|\\tTrain Accuracy:\", end=\" \")\n",
    "    print(\"{:.2f}%\".format(train_acc*100))\n",
    "    if is_logging:\n",
    "        neptune.log_metric(\"Train Loss\", train_loss)\n",
    "    \n",
    "    print(\"\\tValidation Loss:\", end=\" \")\n",
    "    val_loss, val_acc = test(rnn, loss_fn, kwere_val, PARAMS['seq_len'])\n",
    "    print(\"{:.3f}\".format(val_loss), end=\"\\t\")\n",
    "    print(\"\\t|\\tValidation Accuracy:\", end=\" \")\n",
    "    print(\"{:.2f}%\".format(val_acc*100))\n",
    "    if is_logging:\n",
    "        neptune.log_metric(\"Validation Loss\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.478\t\t|\tTest Accuracy: 67.80%\n"
     ]
    }
   ],
   "source": [
    "if len(PARAMS['test_data']) > 0:\n",
    "    print(\"Test Loss:\", end=\" \")\n",
    "    test_loss, test_acc = train(rnn, loss_fn, optimizer, test_data, PARAMS['seq_len'])\n",
    "    print(\"{:.3f}\".format(test_loss), end=\"\\t\")\n",
    "    print(\"\\t|\\tTest Accuracy:\", end=\" \")\n",
    "    print(\"{:.2f}%\".format(test_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
