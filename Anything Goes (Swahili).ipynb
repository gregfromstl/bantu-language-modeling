{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swahili Character-Level Language Model Using PyTorch LSTMs\n",
    "\n",
    "This notebook is nearly identical to \"Anything Goes (Kwere)\". The pretrain-train relationship is just inverted: pre-train on Kwere, fine-tune on Swahili."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results\n",
    "I've had a hard time training on the Swahili data. It seems the data is fairly \"messy\", with a lot of number and other odd characters cluttering the data. Considering the dataset is so large, I thought a lower learning rate would've been ideal, but the lower learning rates performed significantly worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Dictionary containing all parameters for ease of tuning. These will be logged to the neptune logger below.\n",
    "\n",
    "**To add test data, enter the test file name in the `test_data` parameter.**\n",
    "\n",
    "Select Parameter Descriptions:\n",
    " - `experiment_name`: identifier to be used in logging\n",
    " - `tags`: also for logging and filtering trials\n",
    " - `seq_len`: length of character lists fed to the model\n",
    " - `num_layers`: LSTM layers\n",
    " - `carry_hidden_state`: whether or not to perpetuate the hidden state between sequences\n",
    " - `pretrain_lr`: the learning rate to use while pretraining\n",
    " - `kwere_percentage`: the percentage of the Kwere data to pretrain with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'experiment_name': \"Swahili\",\n",
    "    'tags': [\"swahili\", \"anything goes\"],\n",
    "    'epochs': 25,\n",
    "    'hidden_size': 512,\n",
    "    'seq_len': 100,\n",
    "    'num_layers': 4,\n",
    "    'dropout': 0.2,\n",
    "    'lr': 0.01,\n",
    "    'carry_hidden_state': False,\n",
    "    'val_split': 0.3,\n",
    "    'swahili_train': \"./sw-train.txt\",\n",
    "    'pretrain_epochs': 5,\n",
    "    'pretrain_lr': 0.001,\n",
    "    'kwere_percentage': 0, \n",
    "    'kwere': \"./cwe-train.txt\",\n",
    "    'test_data': \"./sw-test.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging\n",
    "For this project I used a logging library / UI called [Neptune.ai](https://neptune.ai/) to track all runs and their respective hyperparameters. Since the API key for this is only in my local `bash_profile`, **this cell will throw an error**, but I'll conditionalize all the logging in the notebook so errors won't be thrown beyond this cell.\n",
    "\n",
    "To view the logs from my runs, visit the project url [here](https://ui.neptune.ai/gregrolwes/Bantu-Language-Modeling/experiments?viewId=standard-view&sortBy=%5B%22timeOfCreation%22%5D&sortDirection=%5B%22descending%22%5D&sortFieldType=%5B%22native%22%5D&sortFieldAggregationMode=%5B%22auto%22%5D&trashed=false&suggestionsEnabled=false&lbViewUnpacked=true&tags=%5B%22swahili%22%2C%22anything%20goes%22%5D). Note projects are tagged with which language they're targeting, and whether or not they using the \"Anything Goes\" or \"From Scratch\" implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://ui.neptune.ai/gregrolwes/Bantu-Language-Modeling/e/BAN-39\n"
     ]
    }
   ],
   "source": [
    "is_logging = False\n",
    "\n",
    "import neptune\n",
    "\n",
    "neptune.init('gregrolwes/Bantu-Language-Modeling')\n",
    "\n",
    "neptune.create_experiment(\n",
    "            name=PARAMS['experiment_name'],\n",
    "            tags=PARAMS['tags'],\n",
    "            params=PARAMS\n",
    "        )\n",
    "\n",
    "# reach this if the above logger initialization passes\n",
    "is_logging = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Seed\n",
    "Make the experiment reproducible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPU Support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class\n",
    "The `Dataset` class generates a list of all unique characters found in the supplied data, number of total characters, number of unique characters, mappings from characters to their respective ID, mappings from chracter IDs to characters for making outputs readable, and a data tensor of every character converted to its ID.\n",
    "\n",
    "The `Dataset` will also generate a `~` character to be used in place of any characters unknown to the model (i.e. anything not in the training set). See the `clean_data` function below.\n",
    "\n",
    "Inputs:\n",
    " - `raw_data`: `string` of all characters from the provided data in order\n",
    " - `device`: `torch.device` of either `cuda` or `cpu`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, raw_data: str, device: torch.device):\n",
    "        self.chars = set(list(set(raw_data)))\n",
    "        self.chars.add('~')\n",
    "        self.data_size, self.vocab_size = len(raw_data), len(self.chars)\n",
    "        print(\"{} characters, {} unique\".format(self.data_size, self.vocab_size))\n",
    "        \n",
    "        self.char_to_idx = { char: idx for idx, char in enumerate(self.chars) }\n",
    "        self.idx_to_char = { idx: char for idx, char in enumerate(self.chars) }\n",
    "        \n",
    "        self.data = torch.tensor([self.char_to_idx[char] for char in list(raw_data)]).unsqueeze(1).to(device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "The `clean_data` function removes any unknown chracters in the provided data and replaces them with the deisgnated unknown chracter of `~`. I'm essentially forfeiting these characters if they ever appear in the testing data, since I likely couldn't get them correct anyway considering the model did not see them during training (unless they appear in the Kwere data, but see my explanation below for that decision).\n",
    "\n",
    "Inputs:\n",
    " - `raw_data`: `string` of raw data read directly from file\n",
    " - `known_chars`: `list` of `string` to be included in the data. Everything not in this list will be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(raw_data: str, known_chars: str) -> str:\n",
    "    cleaned = \"\"\n",
    "    for char in raw_data:\n",
    "        if char not in known_chars:\n",
    "            cleaned += \"~\"\n",
    "        else:\n",
    "            cleaned += char\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "Load the Swahili training data and split based on the provided ratio. Then load the percentage of the Kwere data requested (see `PARAMS`). Finally, if a test file is provided in `PARAMS`, load the test data.\n",
    "\n",
    "The validation, Kwere, and test data are all cleaned of unknown chracters. I chose to exclude any chracters found in the Swahili data but not found in the Swahili training data for the sake of staying as true to the Swahili language as possible (in the event Kwere uses a character that Kwere does not).\n",
    "\n",
    "I am also only training on a subset of the Swahili data for the sake of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Swahili training data:\n",
      "\t2100000 characters, 49 unique\n",
      "Loading Swahili validation data:\n",
      "\t900000 characters, 49 unique\n",
      "Loading testing data:\n",
      "\t3451383 characters, 49 unique\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Swahili training data:\", end=\"\\n\\t\")\n",
    "raw_swahili = open(PARAMS['swahili_train'], 'r').read()[:3000000]\n",
    "swahili_train_size, swahili_val_size = int(len(raw_swahili)*(1-PARAMS['val_split'])), int(len(raw_swahili)*PARAMS['val_split'])\n",
    "\n",
    "swahili_train = Dataset(raw_swahili[:swahili_train_size], device)\n",
    "\n",
    "print(\"Loading Swahili validation data:\", end=\"\\n\\t\")\n",
    "cleaned_swahili_val_data = clean_data(raw_swahili[swahili_train_size:], swahili_train.chars)\n",
    "swahili_val = Dataset(cleaned_swahili_val_data, device)\n",
    "\n",
    "if PARAMS['kwere_percentage'] > 0:\n",
    "    print(\"Loading Kwere data:\", end=\"\\n\\t\")\n",
    "    raw_kwere = open(PARAMS['kwere'], 'r').read()\n",
    "    kwere_size = int(len(raw_kwere) * PARAMS['kwere_percentage'])\n",
    "\n",
    "    cleaned_kwere_data = clean_data(raw_kwere[:kwere_size], swahili_train.chars)\n",
    "    kwere = Dataset(cleaned_kwere_data, device)\n",
    "\n",
    "\n",
    "if len(PARAMS['test_data']) > 0:\n",
    "    print(\"Loading testing data:\", end=\"\\n\\t\")\n",
    "    raw_test = open(PARAMS['test_data'], 'r').read()\n",
    "\n",
    "    cleaned_test_data = clean_data(raw_test, swahili_train.chars)\n",
    "    test_data = Dataset(cleaned_test_data, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Declaration\n",
    "The model is very similar to those I've used in past challenges: a multilayer LSTM with dropout. I've also added the ability to input a hidden state so the state can be carried between sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers, dropout):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(input_size, input_size)\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=input_size, \n",
    "            hidden_size=hidden_size, \n",
    "            num_layers=num_layers,\n",
    "            dropout = dropout if num_layers > 1 else 0\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "    def forward(self, input_seq, hidden_state):\n",
    "        embedding = self.embedding(input_seq)\n",
    "        output, hidden_state = self.lstm(embedding, hidden_state)\n",
    "        output = self.fc(self.dropout(output))\n",
    "        return output, (hidden_state[0].detach(), hidden_state[1].detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function\n",
    "As defined in the challenge requirements, I'm using a cross entropy loss customized to use log base 2 rather than the typical natural log used in PyTorch.\n",
    "\n",
    "I've also added an assertion making sure no probability distribution sums to more than 1/10,000 plus or minus 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy_loss(outputs, targets):\n",
    "    batch_size = outputs.shape[0]\n",
    "    outputs = nn.functional.softmax(outputs, dim=-1)\n",
    "    \n",
    "    for prob_dist_sum in torch.sum(outputs, dim=1):\n",
    "        assert(abs(prob_dist_sum - 1) < 0.0001), \"The sum of all probabilities for a character should be 1.0, but got {}\".format(prob_dist_sum)\n",
    "    \n",
    "    outputs = torch.log2(outputs)\n",
    "    outputs = outputs[range(batch_size), targets]\n",
    "    \n",
    "    return -torch.mean(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Declaration\n",
    "Based on `PARAMS` and the determined `vocab_size` of the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = RNN(\n",
    "    swahili_train.vocab_size, \n",
    "    swahili_train.vocab_size, \n",
    "    PARAMS['hidden_size'], \n",
    "    PARAMS['num_layers'],\n",
    "    PARAMS['dropout'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "Using an Adam optimizer, learning rate set in `PARAMS`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = cross_entropy_loss\n",
    "optimizer = torch.optim.Adam(rnn.parameters(), lr=PARAMS['lr'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Rate Modifier\n",
    "The `set_lr` function is meant to modify the learning rate between pretraining and fine-tuning to avoid overfitting on the Swahili data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_lr(optimizer: torch.optim.Optimizer, lr: int):\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model to GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(49, 49)\n",
       "  (lstm): LSTM(49, 512, num_layers=4, dropout=0.2)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=49, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to check for NaNs, used in debugging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_nan(t: torch.Tensor) -> bool:\n",
    "    if torch.sum(torch.isnan(t)) > 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Function\n",
    "Standard train function taking `seq_len` characters at a time. For each character in the series, the LSTM will predict the next character based on the previous character and the character history (represented by the hidden state). \n",
    "\n",
    "The hidden state is optionally carried between sequences, so events like a sequence ending mid-word should have no negative effect. I've made this optional because while it could help with cutoff words, I think restarting the hidden state every sequence could also be beneficial as a sort of dropout, in the event a particularly difficult sequence causes the hidden state to be thrown off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, data, seq_len):\n",
    "    ptr = 0\n",
    "    n = 0\n",
    "    running_loss = 0\n",
    "    hidden_state = None\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    while ptr + seq_len + 1 < len(data):\n",
    "        input_seq = data[ptr:ptr+seq_len].to(device)\n",
    "        target_seq = data[ptr+1:ptr+seq_len+1].to(device)\n",
    "\n",
    "        if hidden_state is not None:\n",
    "            if has_nan(hidden_state[0]) or has_nan(hidden_state[1]):\n",
    "                hidden_state = None\n",
    "        output, hidden_state = model(input_seq, hidden_state if PARAMS['carry_hidden_state'] else None)\n",
    "\n",
    "        try:\n",
    "            loss = criterion(torch.squeeze(output), torch.squeeze(target_seq))\n",
    "            assert(not torch.isnan(loss)), \"The loss shouldn't be nan\"\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            n += 1\n",
    "        except AssertionError as err:\n",
    "            print(\"An assertion failed, skipping for now but this shouldn't happen often:\\n\\t{}\".format(err))\n",
    "\n",
    "        ptr += seq_len\n",
    "        \n",
    "    return running_loss/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Function\n",
    "Standard test function with optional carried hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, criterion, data, seq_len):\n",
    "    ptr = 0\n",
    "    n = 0\n",
    "    running_loss = 0\n",
    "    hidden_state = None\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    while ptr + seq_len + 1 < len(data):\n",
    "        input_seq = data[ptr:ptr+seq_len]\n",
    "        target_seq = data[ptr+1:ptr+seq_len+1]\n",
    "\n",
    "        if hidden_state is not None:\n",
    "            if has_nan(hidden_state[0]) or has_nan(hidden_state[1]):\n",
    "                hidden_state = None\n",
    "        output, hidden_state = model(input_seq, hidden_state if PARAMS['carry_hidden_state'] else None)\n",
    "\n",
    "        try:\n",
    "            loss = criterion(torch.squeeze(output), torch.squeeze(target_seq))\n",
    "            assert(not torch.isnan(loss)), \"The loss shouldn't be nan\"\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            n += 1\n",
    "        except AssertionError as err:\n",
    "            print(\"An assertion failed, skipping for now but this shouldn't happen often:\\n\\t{}\".format(err))\n",
    "\n",
    "        ptr += seq_len\n",
    "        \n",
    "    return running_loss/n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function Verification\n",
    "Based on the equation for cross entropy, a randomized model's loss should on average be $log_2(vocab\\_size)$.\n",
    "\n",
    "This number should also be the target to verify that the model is learning. Any loss lower than this value has learned a non-zero amount."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size is 49, so cross entropy with no training should be approximately 5.614709844115208\n",
      "Untrained loss: 5.613650491827722\n"
     ]
    }
   ],
   "source": [
    "print(\"Vocab size is {}, so cross entropy with no training should be approximately {}\".format(swahili_train.vocab_size, math.log(swahili_train.vocab_size, 2)))\n",
    "print(\"Untrained loss:\", end=\" \")\n",
    "print(test(rnn, loss_fn, swahili_val, PARAMS['seq_len']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "if PARAMS['kwere_percentage'] > 0:\n",
    "    set_lr(optimizer, PARAMS['pretrain_lr'])\n",
    "    \n",
    "    for epoch in range(0, PARAMS['pretrain_epochs']):\n",
    "        print(\"-\"*3 + \" Pretrain Epoch {} \".format(epoch+1) + \"-\"*17)\n",
    "\n",
    "        print(\"\\tPretrain Loss:\", end=\" \")\n",
    "        pretrain_loss = train(rnn, loss_fn, optimizer, kwere, PARAMS['seq_len'])\n",
    "        print(pretrain_loss)\n",
    "        \n",
    "        if is_logging:\n",
    "            neptune.log_metric(\"Pretrain Loss\", pretrain_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Epoch 1 -------------------------\n",
      "\tTraining Loss: 4.267908933599924\n",
      "\tValidation Loss: 4.332783218065439\n",
      "--- Epoch 2 -------------------------\n",
      "\tTraining Loss: 4.228882867873604\n",
      "\tValidation Loss: 4.2758675821755565\n",
      "--- Epoch 3 -------------------------\n",
      "\tTraining Loss: 4.206150354252037\n",
      "\tValidation Loss: "
     ]
    }
   ],
   "source": [
    "set_lr(optimizer, PARAMS['lr'])\n",
    "\n",
    "for epoch in range(0, PARAMS['epochs']):\n",
    "    print(\"-\"*3 + \" Epoch {} \".format(epoch+1) + \"-\"*25)\n",
    "    \n",
    "    print(\"\\tTraining Loss:\", end=\" \")\n",
    "    train_loss = train(rnn, loss_fn, optimizer, swahili_train, PARAMS['seq_len'])\n",
    "    print(train_loss)\n",
    "    if is_logging:\n",
    "        neptune.log_metric(\"Train Loss\", train_loss)\n",
    "    \n",
    "    print(\"\\tValidation Loss:\", end=\" \")\n",
    "    val_loss = test(rnn, loss_fn, swahili_val, PARAMS['seq_len'])\n",
    "    print(val_loss)\n",
    "    if is_logging:\n",
    "        neptune.log_metric(\"Validation Loss\", val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data in globals():\n",
    "    print(\"Testing Loss:\", end=\" \")\n",
    "    test_loss = train(rnn, loss_fn, optimizer, test_data, PARAMS['seq_len'])\n",
    "    print(test_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
