{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kwere Character-Level Language Vanilla N-Gram Model\n",
    "\n",
    "**I started with this implementation but it's performance is suboptimal. I left it just for documentation. Please see the other \"From Scratch\" implementations for better performance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters\n",
    "Dictionary containing all parameters for ease of tuning. These will be logged to the neptune logger below.\n",
    "\n",
    "**To add test data, enter the test file name in the `test_data` parameter.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PARAMS = {\n",
    "    'experiment_name': \"Kwere\",\n",
    "    'tags': [\"kwere\", \"from scratch\"],\n",
    "    'n': 5,\n",
    "    'train_iterations': 5,\n",
    "    'carry_hidden_state': False,\n",
    "    'val_split': 0.3,\n",
    "    'kwere_train': \"./cwe-train.txt\",\n",
    "    'pretrain_iterations': 5,\n",
    "    'pretrain_percentage': 0.05, \n",
    "    'swahili': \"./sw-train.txt\",\n",
    "    'test_data': \"./cwe-test.txt\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only import. Used for the log function to compute cross entropy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Class\n",
    "The `Dataset` class generates a list of all unique characters found in the supplied data, number of total characters, number of unique characters, mappings from characters to their respective ID, mappings from chracter IDs to characters for making outputs readable, and a data tensor of every character converted to its ID.\n",
    "\n",
    "The `Dataset` will also generate a `~` character to be used in place of any characters unknown to the model (i.e. anything not in the training set). See the `clean_data` function below.\n",
    "\n",
    "Inputs:\n",
    " - `raw_data`: `string` of all characters from the provided data in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset():\n",
    "    def __init__(self, raw_data: str):\n",
    "        self.chars = set(list(set(raw_data)))\n",
    "        self.chars.add('~')\n",
    "        self.data_size, self.vocab_size = len(raw_data), len(self.chars)\n",
    "        print(\"{} characters, {} unique\".format(self.data_size, self.vocab_size))\n",
    "        \n",
    "        self.char_to_idx = { char: idx for idx, char in enumerate(self.chars) }\n",
    "        self.idx_to_char = { idx: char for idx, char in enumerate(self.chars) }\n",
    "        \n",
    "        self.data = [self.char_to_idx[char] for char in list(raw_data)]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning\n",
    "The `clean_data` function removes any unknown chracters in the provided data and replaces them with the deisgnated unknown chracter of `~`. I'm essentially forfeiting these characters if they ever appear in the testing data, since I likely couldn't get them correct anyway considering the model did not see them during training (unless they appear in the Kwere data, but see my explanation below for that decision).\n",
    "\n",
    "Inputs:\n",
    " - `raw_data`: `string` of raw data read directly from file\n",
    " - `known_chars`: `list` of `string` to be included in the data. Everything not in this list will be replaced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(raw_data: str, known_chars: str) -> str:\n",
    "    cleaned = \"\"\n",
    "    for char in raw_data:\n",
    "        if char not in known_chars:\n",
    "            cleaned += \"~\"\n",
    "        else:\n",
    "            cleaned += char\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "Load the Swahili training data and split based on the provided ratio. Then load the percentage of the Kwere data requested (see `PARAMS`). Finally, if a test file is provided in `PARAMS`, load the test data.\n",
    "\n",
    "The validation, Kwere, and test data are all cleaned of unknown chracters. I chose to exclude any chracters found in the Swahili data but not found in the Swahili training data for the sake of staying as true to the Swahili language as possible (in the event Kwere uses a character that Kwere does not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Kwere training data:\n",
      "\t422402 characters, 32 unique\n",
      "Loading Kwere validation data:\n",
      "\t181030 characters, 32 unique\n",
      "Loading Swahili data:\n",
      "\t1963053 characters, 32 unique\n",
      "Loading Testing data:\n",
      "\t61717 characters, 32 unique\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading Kwere training data:\", end=\"\\n\\t\")\n",
    "raw_kwere = open(PARAMS['kwere_train'], 'r').read()\n",
    "kwere_train_size, kwere_val_size = int(len(raw_kwere)*(1-PARAMS['val_split'])), int(len(raw_kwere)*PARAMS['val_split'])\n",
    "\n",
    "train_data = Dataset(raw_kwere[:kwere_train_size])\n",
    "\n",
    "print(\"Loading Kwere validation data:\", end=\"\\n\\t\")\n",
    "cleaned_kwere_val_data = clean_data(raw_kwere[kwere_train_size:], train_data.chars)\n",
    "val_data = Dataset(cleaned_kwere_val_data)\n",
    "\n",
    "\n",
    "if PARAMS['pretrain_percentage'] > 0:\n",
    "    print(\"Loading Swahili data:\", end=\"\\n\\t\")\n",
    "    raw_swahili = open(PARAMS['swahili'], 'r').read()\n",
    "    swahili_size = int(len(raw_swahili) * PARAMS['pretrain_percentage'])\n",
    "\n",
    "    cleaned_swahili_data = clean_data(raw_swahili[:swahili_size], train_data.chars)\n",
    "    pretrain_data = Dataset(cleaned_swahili_data)\n",
    "\n",
    "\n",
    "if len(PARAMS['test_data']) > 0:\n",
    "    print(\"Loading Testing data:\", end=\"\\n\\t\")\n",
    "    raw_test = open(PARAMS['test_data'], 'r').read()\n",
    "\n",
    "    cleaned_test_data = clean_data(raw_test, train_data.chars)\n",
    "    test_data = Dataset(cleaned_test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_matrix(vocab: list, n: int):\n",
    "    if n > 0:\n",
    "        return {i:init_matrix(vocab, n-1) for i in vocab}\n",
    "    else:\n",
    "        return {i:0 for i in vocab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def increment_count(char: str, sequence: list, count_matrix: dict) -> list:\n",
    "    if len(sequence) == 0:\n",
    "        count_matrix[char] += 1\n",
    "    else:\n",
    "        count_matrix[sequence[0]] = increment_count(char, sequence[1:], count_matrix[sequence[0]]) \n",
    "    return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_counts(data: Dataset, n: int, count_matrix: dict):\n",
    "    for idx, char in enumerate(data[n:]):\n",
    "        idx = n + idx\n",
    "        sequence = data[idx-n:idx]\n",
    "        \n",
    "        count_matrix = increment_count(data[idx], sequence, count_matrix)\n",
    "    return count_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_matrix = init_matrix(train_data.idx_to_char.keys(), PARAMS['n'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting on pretrain data...\n",
      "Fitting on train data...\n"
     ]
    }
   ],
   "source": [
    "print(\"Fitting on pretrain data...\")\n",
    "count_matrix = iterate_counts(pretrain_data, PARAMS['n'], count_matrix)\n",
    "print(\"Fitting on train data...\")\n",
    "count_matrix = iterate_counts(train_data, PARAMS['n'], count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilities_from_counts(counts: dict):\n",
    "    # add one smoothing\n",
    "    counts = {key:counts[key]+1 for key in counts.keys()}\n",
    "    \n",
    "    probabilities = {key: counts[key] / sum(counts.values()) for key in counts.keys()}\n",
    "    prob_sum = sum(probabilities.values())\n",
    "    assert(abs(prob_sum - 1) < 0.0001), \"Probabilities should sum to 1.0 but got {}\".format(prob_sum)\n",
    "    \n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_probabilities_for_sequence(sequence: list, count_matrix: dict):\n",
    "    if len(sequence) == 0:\n",
    "        return probabilities_from_counts(count_matrix)\n",
    "    else:\n",
    "        return get_probabilities_for_sequence(sequence[1:], count_matrix[sequence[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss(target_prob):\n",
    "    return -math.log(target_prob, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval(data: Dataset, n: int, count_matrix: dict):\n",
    "    print(\"Evaluating...\")\n",
    "    \n",
    "    counter = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    for idx, char in enumerate(data[n:]):\n",
    "        idx = n + idx\n",
    "        sequence = data[idx-n:idx]\n",
    "\n",
    "        probabilities: dict = get_probabilities_for_sequence(sequence, count_matrix)\n",
    "        pred: str = max(probabilities, key=probabilities.get)\n",
    "        target: str = data[idx]\n",
    "        target_prob: float = probabilities[target]\n",
    "        \n",
    "        running_loss += calc_loss(target_prob)\n",
    "        counter += 1\n",
    "        \n",
    "    return running_loss / counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating...\n",
      "Train Loss:  2.2392918598291423\n",
      "Evaluating...\n",
      "Validation Loss:  3.418253588269885\n"
     ]
    }
   ],
   "source": [
    "train_loss, train_acc = eval(train_data, PARAMS['n'], count_matrix)\n",
    "print(\"Train Loss: {}\\t\\t|\\tTrain Accuracy: {}%\".format(train_loss, train_acc*100))\n",
    "\n",
    "val_loss = eval(val_data, PARAMS['n'], count_matrix)\n",
    "print(\"Validation Loss: {}\\t\\t|\\tValidation Accuracy: {}%\".format(val_loss, val_acc*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if test_data in globals():\n",
    "    test_loss = eval(val_data, PARAMS['n'], count_matrix)\n",
    "    print(\"Validation Loss: \", val_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
